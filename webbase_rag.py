# -*- coding: utf-8 -*-
"""webbase_rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tU19zWe6o90dOZOyye2xDT7c3ppAUnBU
"""

pip install faiss-cpu langchain-community langchain-groq

from langchain_core.prompts import PromptTemplate
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader,CSVLoader,WebBaseLoader
from langchain_core.output_parsers import StrOutputParser
from langchain.schema.runnable import RunnableLambda,RunnablePassthrough,RunnableParallel
import re

import os
from google.colab import userdata
os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')

"""## Define Model and Embeddings"""

llm=ChatGroq(
    model='llama-3.1-8b-instant',
    temperature=.3,
    timeout=10,
    max_retries=2,
    verbose=True
)
embeddings=HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-mpnet-base-v2",

)

"""Loader and Splitter"""

## Define Loader
url='https://www.axisbank.com/fixed-deposit-interest-rate'
loader=WebBaseLoader(url)
docs=loader.load()

# Clean the documents (remove promotional content, extra whitespace)
def clean_text(text):
    # Remove common promotional phrases (customize as needed)
    # text = re.sub(r'Apply Now|Get quick & easy|T&C apply', '', text, flags=re.IGNORECASE)
    # Remove excessive whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    return text

## Cleaned list
cleaned_text_list = [clean_text(doc.page_content) for doc in docs]

type(cleaned_text_list)

splitter=RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=['\n\n','\n',' ','']
    )

chunks=splitter.split_text(cleaned_text_list[0])

len(chunks)

"""### Vector Store and Retriever"""

vector_store=FAISS.from_texts(chunks,embeddings)

retriever=vector_store.as_retriever()

res=retriever.invoke("What is the interest rate for fixed deposit")

res[2].page_content

for result in res:
  print(result.page_content)
  print('-'*100)

"""## Context Prompt and LLM response"""

prompt=PromptTemplate(
    template=
    """
    Please answer from the provided context only and in concise only dont explain much details . If answer is insuficient or not availabe in context  simply say "I dont know"\n
    context :{context}
    question :{question}
    """,
    input_variables=['context','question']
)

parser=StrOutputParser()

query ="What is interest rate for 1year fixed deposit "

## Chain

ret_result=retriever.invoke(query)

for result in ret_result:
  print(result.page_content)
  print('-'*100)

## Clean the the output repsonse from retriever
def cleaned_text(text):
  clean_txt='\n\n'.join(chunk.page_content for chunk in text)

  return clean_txt

## We nned to create parallel chain for context and query passing throgh retriever

parallel_chain=RunnableParallel(
    {'context':retriever | RunnableLambda(cleaned_text),
     'question':RunnablePassthrough()}
)

chain= parallel_chain | prompt | llm | parser

"""## using Retrieval Chain"""

from langchain.chains import RetrievalQA

# Initialize the RetrievalQA chain
chain1 = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    input_key="question",
    return_source_documents=True  # Return source documents for inspection
)

final_chain=chain1 | prompt | llm | parser

# response=final_chain.invoke({"question": query})

response

"""## Chat GPT Approach"""

from langchain_core.prompts import PromptTemplate
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain.chains import RetrievalQA
import re

# Step 1: Define Loader
url = 'https://www.axisbank.com/fixed-deposit-interest-rate'
loader = WebBaseLoader(url)
docs = loader.load()  # Load the documents from the web

# Step 2: Clean the Documents
def clean_text(documents):
    """
    Clean and process the page_content of a list of Document objects.
    """
    if not documents:
        return []

    cleaned_texts = []
    for doc in documents:
        if hasattr(doc, "page_content"):
            # Clean page content
            clean_content = re.sub(r'\s+', ' ', doc.page_content).strip()
            cleaned_texts.append(clean_content)
    return cleaned_texts

cleaned_texts = clean_text(docs)

# Step 3: Split the Text into Chunks
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", " ", ""]
)

chunks = []
for text in cleaned_texts:
    chunks.extend(splitter.split_text(text))

# Step 4: Embed the Chunks
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")
vector_store = FAISS.from_texts(chunks, embeddings)

# Step 5: Set Up the Retriever
retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 5})

# Step 6: Define the Prompt and LLM
prompt_template = """
Answer the question using only the provided context. Be concise and do not explain in detail.
If the answer is not in the context, respond with: "I don't know."

Context:
{context}

Question:
{question}
"""

prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

llm = ChatGroq(
    model='llama-3.1-8b-instant',
    temperature=0.3,
    timeout=10,
    max_retries=2,
    verbose=True
)

# Step 7: Define the Chain
qa_chain = RetrievalQA.from_chain_type(
    retriever=retriever,
    llm=llm,
    chain_type_kwargs={"prompt": prompt},
    return_source_documents=True  # Optional, to see source context
)

# Step 8: Query the Chain
query = "What is the interest rate for a 1-year fixed deposit?"
response = qa_chain.invoke(query)

# Output the result
print("Response:", response.get("result", "No response available"))

query="What is the domestic fixed deposit rates for less than 3 years"
response=qa_chain.invoke(query)
print(response.get("result","No response available"))

"""## Now using Pdf loader with webbased approach"""

pip install --upgrade pdfminer.six unstructured

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from langchain_community.document_loaders import WebBaseLoader, OnlinePDFLoader,UnstructuredPDFLoader,PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_groq import ChatGroq
from google.colab import userdata
import re

main_url = 'https://www.axisbank.com/fixed-deposit-interest-rate'
response = requests.get(main_url)
html_content = response.text
soup = BeautifulSoup(html_content, 'html.parser')
pdf_links = [urljoin(main_url, a['href']) for a in soup.find_all('a', href=True) if a['href'].endswith('.pdf')]

main_loader = WebBaseLoader(main_url)
main_docs = main_loader.load()

pdf_docs = []
for pdf_url in pdf_links:
    response = requests.get(pdf_url)
    with open(f"temp_{pdf_url.split('/')[-1]}", "wb") as f:
        f.write(response.content)
    pdf_loader = PyPDFLoader(f"temp_{pdf_url.split('/')[-1]}")
    pdf_docs.extend(pdf_loader.load())

all_docs = main_docs + pdf_docs

def clean_text(documents):
    cleaned_docs = []
    for doc in documents:
        if hasattr(doc, "page_content"):
            clean_content = re.sub(r'\s+', ' ', doc.page_content).strip()
            doc.page_content = clean_content
            cleaned_docs.append(doc)
    return cleaned_docs

cleaned_docs = clean_text(all_docs)

splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", " ", ""]
)
split_docs = splitter.split_documents(cleaned_docs)

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")
vector_store = FAISS.from_documents(split_docs, embeddings)

retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 5})

prompt_template = """
Answer the question using only the provided context. Be concise and do not explain in detail.
If the answer is not in the context, respond with: "I don't know."

Context:
{context}

Question:
{question}
"""
prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

api_key = userdata.get('GROQ_API_KEY')
llm = ChatGroq(
    api_key=api_key,
    model='llama-3.1-8b-instant',
    temperature=0.3,
    timeout=10,
    max_retries=2,
    verbose=True
)

qa_chain = RetrievalQA.from_chain_type(
    retriever=retriever,
    llm=llm,
    chain_type_kwargs={"prompt": prompt},
    return_source_documents=True,
    input_key="question"
)

query = "What is the interest rate for a 3-year fixed deposit?"

result = qa_chain.invoke({"question": query})
print("Answer:", result["result"])
print("Sources:")
for doc in result["source_documents"]:
    print(doc.metadata["source"])

"""## Uisng Unstructured PDF"""

pip install pdfminer.six==20221105 pi-heif

pip install "unstructured[pdf]"

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from langchain_community.document_loaders import WebBaseLoader, UnstructuredPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_groq import ChatGroq
from google.colab import userdata
import re

# Fetch webpage and PDF links
main_url = 'https://www.axisbank.com/fixed-deposit-interest-rate'
response = requests.get(main_url)
soup = BeautifulSoup(response.text, 'html.parser')
pdf_links = [urljoin(main_url, a['href']) for a in soup.find_all('a', href=True) if a['href'].endswith('.pdf')]

# Load web content
main_loader = WebBaseLoader(main_url)
main_docs = main_loader.load()

# Load PDFs
pdf_docs = []
for pdf_url in pdf_links:
    pdf_file = f"temp_{pdf_url.split('/')[-1]}"
    response = requests.get(pdf_url)
    with open(pdf_file, "wb") as f:
        f.write(response.content)
    pdf_loader = UnstructuredPDFLoader(pdf_file)
    pdf_docs.extend(pdf_loader.load())

# Combine documents
all_docs = main_docs + pdf_docs

# Clean documents
def clean_text(documents):
    cleaned_docs = []
    for doc in documents:
        if hasattr(doc, "page_content"):
            clean_content = re.sub(r'\s+', ' ', doc.page_content).strip()
            doc.page_content = clean_content
            cleaned_docs.append(doc)
    return cleaned_docs

cleaned_docs = clean_text(all_docs)

# Split documents
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
split_docs = splitter.split_documents(cleaned_docs)

# Embed and store
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")
vector_store = FAISS.from_documents(split_docs, embeddings)

# Set up retriever
retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 10})

# Define prompt
prompt_template = """
Provide the exact interest rate for the given fixed deposit tenure using the provided context. Answer with the numerical rate (e.g., 7.10% p.a.) or 'Not found' if the rate is unavailable.

Context:
{context}

Question:
{question}
"""
prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

# Initialize LLM
api_key = userdata.get('GROQ_API_KEY')
llm = ChatGroq(api_key=api_key, model='llama3-70b-8192')

# Set up chain
qa_chain = RetrievalQA.from_chain_type(
    retriever=retriever,
    llm=llm,
    chain_type_kwargs={"prompt": prompt},
    return_source_documents=True,
    input_key="question"
)

# Query
query = "what is FD Interest rate for NRE deposit for 15months period"
result = qa_chain.invoke({"question": query})

# Output
print("Answer:", result["result"])
print("Sources:")
for doc in result["source_documents"]:
    print(doc.metadata["source"])

